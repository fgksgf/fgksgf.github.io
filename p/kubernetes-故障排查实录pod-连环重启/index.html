<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="How I Cracked the Kubernetes Pod Restart Conundrum"><title>Kubernetes 故障排查实录：Pod 连环重启</title><link rel=canonical href=https://fgksgf.github.io/p/kubernetes-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%AE%9E%E5%BD%95pod-%E8%BF%9E%E7%8E%AF%E9%87%8D%E5%90%AF/><link rel=stylesheet href=/scss/style.min.833d6eed45de56f48306bf57268d5b8cdfc8a60e8e7bdc99810464fcd033f7c6.css><meta property='og:title' content="Kubernetes 故障排查实录：Pod 连环重启"><meta property='og:description' content="How I Cracked the Kubernetes Pod Restart Conundrum"><meta property='og:url' content='https://fgksgf.github.io/p/kubernetes-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%AE%9E%E5%BD%95pod-%E8%BF%9E%E7%8E%AF%E9%87%8D%E5%90%AF/'><meta property='og:site_name' content="Hoshea's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='kubernetes'><meta property='article:published_time' content='2024-05-02T00:00:00+00:00'><meta property='article:modified_time' content='2024-05-02T00:00:00+00:00'><meta name=twitter:title content="Kubernetes 故障排查实录：Pod 连环重启"><meta name=twitter:description content="How I Cracked the Kubernetes Pod Restart Conundrum"><link rel="shortcut icon" href=/favicon.ico><script async src="https://www.googletagmanager.com/gtag/js?id=G-57JLZRD5PD"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-57JLZRD5PD")}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_aaf66a8cc8afe13b.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Hoshea's Blog</a></h1><h2 class=site-description>Do something today that your future self will thank you for.</h2></div></header><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=about><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=search><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#诡异的-pod-重启现象>诡异的 Pod 重启现象</a></li><li><a href=#抽丝剥茧循序渐进>抽丝剥茧，循序渐进</a></li><li><a href=#拨开迷雾找到元凶>拨开迷雾，找到元凶</a></li><li><a href=#亡羊补牢永绝后患>亡羊补牢，永绝后患</a></li><li><a href=#总结与反思>总结与反思</a></li><li><a href=#references>References</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/tech/>Tech</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/kubernetes-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%AE%9E%E5%BD%95pod-%E8%BF%9E%E7%8E%AF%E9%87%8D%E5%90%AF/>Kubernetes 故障排查实录：Pod 连环重启</a></h2><h3 class=article-subtitle>How I Cracked the Kubernetes Pod Restart Conundrum</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published datetime=2024-05-02T00:00:00Z>May 02, 2024</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>4 minute read</time></div></footer></div></header><section class=article-content><h2 id=诡异的-pod-重启现象>诡异的 Pod 重启现象</h2><p>几个月前，我遇到了一个令人困惑的 Kubernetes 故障：在一周的时间里，我几乎每天都会收到不同 Pod 出现 <code>CrashLoopBackOff</code> 状态的告警。通过 <code>kubectl describe pod</code> 查看重启的原因均是容器异常退出。奇怪的是，虽然这些 Pod 在同一个 K8s 集群，但属于不同的 Deployment 和 Namespace，表面上无直接的关联。然而只要我执行 <code>kubectl delete pod</code> 命令删除故障 Pod，让其所属的 Deployment 重新创建，Pod 便会恢复正常。</p><p>起初，我通过简单地删除 Pod 来应对告警，但问题并没有收敛，反而持续发生，这暗示着可能存在更深层次的系统性问题。为了彻底解决问题，标本兼治，我决定深入调查，找出根本原因。</p><h2 id=抽丝剥茧循序渐进>抽丝剥茧，循序渐进</h2><p>首先，通过查看日志和 K8s events，发现均是因为网络问题导致 Pod 重启，例如：</p><ul><li>Pod A 日志显示：<code>dial tcp: lookup kube-apiserver on 172.20.0.10:53: no such host</code>。该应用依赖 K8s apiserver 才能正常工作，但日志表明容器无法解析 IP 地址（尽管集群内的 coredns 组件运行正常），因此异常退出进而不断重启</li><li>Pod B 的日志为 <code>timeout: failed to connect service ":50051" within 5s</code>，其中 <code>50051</code> 是容器的 liveness probe 端口，由于 kubelet 一直探测失败所以不断重启容器</li></ul><p>由于 Pod B 属于 DaemonSet，我注意到了这两个 Pod 都运行在 Node C 上。回顾之前的告警，发现受影响的 Pod 也都是跑在 Node C 上。而之前的 <code>kubectl delete pod</code> 操作恰好使得告警的 Pod 被重建后调度到了其他 Node 上，从而恢复了正常，这表明问题根源在 Node C。</p><p>于是我立即使用<code>kubectl cordon</code>将 Node 标记为不可调度，在接下来的几天果然没有再出现类似的告警，但根本原因还没有定位出来。</p><p>我查看了 Node 的 metrics 和 events，资源使用情况正常，未发现明显瓶颈。最后在 Node 的 <code>/var/log/messages</code> 中发现了关键的日志信息：&ldquo;nf_conntrack: nf_conntrack: table full, dropping packet&rdquo;。</p><p>nf_conntrack 是 Linux 系统中 Netfilter 的一个关键组件，用于跟踪所有网络连接。上述日志表明连接跟踪表（conntrack table）已满，操作系统无法为新的网络连接创建条目。conntrack table 满的原因可能是 Node 上的某个异常 Pod 占用了大量连接。该 Pod 可能建立了大量连接，但未及时释放，导致 conntrack table 无法回收连接。当 Node 上的其他 Pod 尝试建立新连接时，由于 conntrack table 已满，连接失败，或是无法访问 coredns 解析 IP 地址或是 kubelet 无法探活成功，进而导致 Pod 重启。</p><h2 id=拨开迷雾找到元凶>拨开迷雾，找到元凶</h2><p>定位到了问题，接下来就是找出 Node 上的异常 Pod。</p><p>由于 Kubernetes 使用了网络命名空间来确保 Pod 之间的网络隔离，因此直接在 Node 查看连接状态可能无法准确反映单个 Pod 的网络活动，我们需要进入到 Pod 的网络命名空间去查看连接情况。故基本思路为：逐个检查 Pod 的网络命名空间，查看当前建立的连接数量。</p><p>首先通过<code>kubectl describe node</code>拿到 Node 上所有的 Pod 信息，再使用以下命令拿到容器 ID：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 由于 Pod 中所有容器共享同一命名空间，只需查询一个容器即可</span>
</span></span><span class=line><span class=cl>kubectl get pod &lt;POD-NAME&gt; -n &lt;NAMESPACE&gt; -o <span class=nv>jsonpath</span><span class=o>=</span><span class=s1>&#39;{.status.containerStatuses[0].containerID}&#39;</span>
</span></span></code></pre></div><p>然后在 Node 上执行以下命令：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 获取容器的 PID：</span>
</span></span><span class=line><span class=cl>crictl inspect --template <span class=s2>&#34;{{ .info.pid }}&#34;</span> -o go-template &lt;ContainerID&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 统计该 Pod 网络命名空间中所有打开的网络连接数</span>
</span></span><span class=line><span class=cl>nsenter -t &lt;pid&gt; -n netstat -anp <span class=p>|</span> wc -l
</span></span></code></pre></div><p>最终发现，有一个 Pod 建立了异常多的连接，明显高于该 Node 上其他 Pod。</p><p>查看对应的代码，该应用是一个 K8s Operator，它在每一次 reconcile 的时候都会创建一个 <code>http.Client</code> 并发起若干次请求。由于没有进行额外的设置，下面这些配置均会使用默认值，这意味着每次 reconcile 都可能导致连接泄漏：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=c1>// MaxIdleConns controls the maximum number of idle (keep-alive)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=c1>// connections across all hosts. Zero means no limit.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nx>MaxIdleConns</span><span class=w> </span><span class=kt>int</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c1>// IdleConnTimeout is the maximum amount of time an idle</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=c1>// (keep-alive) connection will remain idle before closing</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=c1>// itself.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=c1>// Zero means no limit.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nx>IdleConnTimeout</span><span class=w> </span><span class=nx>time</span><span class=p>.</span><span class=nx>Duration</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c1>// DisableKeepAlives, if true, disables HTTP keep-alives and</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=c1>// will only use the connection to the server for a single</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=c1>// HTTP request.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=c1>//
</span></span></span><span class=line><span class=cl><span class=c1>// This is unrelated to the similarly named TCP keep-alives.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nx>DisableKeepAlives</span><span class=w> </span><span class=kt>bool</span><span class=w>
</span></span></span></code></pre></div><h2 id=亡羊补牢永绝后患>亡羊补牢，永绝后患</h2><p>为了避免类似问题再次发生，我采取了以下措施：</p><ul><li>修改代码，对闲置连接的相关配置项进行合理设置而非使用默认值</li><li>增加了对 Node conntrack table 使用情况的监控面板，并添加了相应的告警规则 (node-exporter 暴露了 conntrack 相关的 metrics):</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl>- <span class=nt>alert</span><span class=p>:</span><span class=w> </span><span class=l>NodeHighNumberConntrackEntriesUsed</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>annotations</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>description</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;{{ $value }} of conntrack entries are used.&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>runbook_url</span><span class=p>:</span><span class=w> </span><span class=l>https://runbooks.prometheus-operator.dev/runbooks/node/nodehighnumberconntrackentriesused/</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>summary</span><span class=p>:</span><span class=w> </span><span class=l>Number of conntrack are getting close to the limit.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>expr</span><span class=p>:</span><span class=w> </span><span class=l>node_nf_conntrack_entries / node_nf_conntrack_entries_limit &gt; 0.7</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>for</span><span class=p>:</span><span class=w> </span><span class=l>10m</span><span class=w>
</span></span></span></code></pre></div><ul><li>（可选）根据节点的内存调整 conntrack table 大小：</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>vim /etc/sysctl.conf
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>net.netfilter.nf_conntrack_max <span class=o>=</span> &lt;value&gt;
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>sysctl -p /etc/sysctl.conf
</span></span></code></pre></div><h2 id=总结与反思>总结与反思</h2><p>在本次故障排查的过程中，有两个关键行动点：</p><ul><li><strong>识别模式</strong>：通过观察多个故障案例，找出了共同点，有效缩小了问题排查的范围</li><li><strong>多角度排查</strong>：在问题排查过程中，除了分析 Node 的 metrics、events 和 kubelet 日志外，还检查了 Node 的系统日志，这提供了额外的视角和信息</li></ul><p>整个过程凸显了 Kubernetes 生态的复杂性。为了成功地发现和解决问题，我们不仅需要深入理解 K8s 各组件的工作原理，还需要具备深入的操作系统级别知识。这些知识帮助我们穿透表象，直击问题核心。</p><p>总的来说，尽管问题的出现带来了不小的挑战，但解决过程本身也是一次宝贵的学习经历，希望你也能有所收获！</p><h2 id=references>References</h2><ul><li><a class=link href=https://thenewstack.io/hackers-guide-kubernetes-networking/ target=_blank rel=noopener>https://thenewstack.io/hackers-guide-kubernetes-networking/</a></li></ul></section><footer class=article-footer><section class=article-tags><a href=/tags/kubernetes/>Kubernetes</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-ND 4.0</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/mirrord-%E5%AE%9E%E6%88%98%E6%8C%87%E5%8D%97-%E5%A6%82%E4%BD%95%E5%A4%A7%E5%B9%85%E6%8F%90%E5%8D%87%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BC%80%E5%8F%91%E6%95%88%E7%8E%87/><div class=article-details><h2 class=article-title>mirrord 实战指南: 如何大幅提升云原生开发效率？</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=fgksgf/blog-comment-system issue-term=pathname crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2025 Hoshea's Blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.33.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.c922af694cc257bf1ecc41c0dd7b0430f9114ec280ccf67cd2c6ad55f5316c4e.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script><script async src="https://www.googletagmanager.com/gtag/js?id=UA-118341733-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-118341733-1")</script></body></html>