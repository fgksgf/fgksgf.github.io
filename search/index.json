[{"content":"前言 最近在开发测试时，频繁使用到 mirrord 这个工具，从最初的惊喜到遇到各种坑，再到逐渐掌握，深感这是一个能够显著提升开发效率的神器。因此写下这篇文章分享一下自己的使用经验，希望能对做云原生开发的朋友有所帮助。\n云原生开发的痛点 在云原生开发中，存在着以下痛点：\n本地开发环境难以完整模拟云环境（比如调用其他服务，使用云环境的权限等），导致实际上线后出问题。 反馈链路长，调试困难。每次修改代码后，需要经历 构建镜像 -\u0026gt; 推送仓库 -\u0026gt; 部署对应 K8s 资源 -\u0026gt; 等待 Pod 启动 -\u0026gt; 查看日志 的漫长过程。如果发现了问题，需要重复这个过程，开发效率低下。 而 mirrord 正是为解决这些问题而生的，它的核心能力是：在本地运行代码，但在云环境的上下文中执行。\nMirrord 简介 Mirrord 是一个开源项目，它通过进程级注入，让本地进程仿佛直接“寄生”在 K8s 的 Pod 中，共享其网络、文件系统和环境变量。借助 mirrord，可以做到:\n本地运行代码,云端测试效果：无需部署即可在真实的云环境中测试代码 秒级反馈：修改代码后直接本地运行,立即看到效果，告别漫长的 CI/CD 等待 使用本地调试工具：在 IDE 中打断点、单步调试，就像调试本地应用一样简单 真实的依赖访问：本地进程可以直接访问远程集群中的其他微服务，以及使用云环境的权限 技术原理 mirrord 主要包含以下两个核心组件：\n运行在开发者本地机器上的 mirrord-layer 临时部署在远程 Kubernetes 集群中的 mirrord-agent mirrord-layer mirrord-layer 是一个动态链接库，它利用了 Unix/Linux 系统加载器的预加载特性，通过设置一个特殊的环境变量，将 mirrord-layer 注入到本地进程，从而 hook 一系列关键的系统调用函数，包括：网络 I/O、文件系统操作和环境变量读取。\nmirrord-agent mirrord-agent 是一个用 Rust 编写的高性能代理，运行在 K8s 集群中的目标 Pod（即要“寄生”的 Pod）所在节点上，并与目标 Pod 运行在同一个 Linux 命名空间中。这使得 mirrord-agent 既可以镜像（Mirror）目标 Pod 的流量（即复制一份给本地，不影响线上业务），也可以拦截（Steal）流量（即完全接管流量，适合调试特定请求）。同时，它还能代理文件系统的读写操作。\n值得注意的是，mirrord-agent 是随着本地调试进程的启动而临时创建的，当本地进程结束后，Agent Pod 会自动销毁，不会在集群中留下残留垃圾。\n工作流程 本地的 mirrord-layer 和远程的 mirrord-agent 搭建起一条双向的数据通道，使得本地进程仿佛直接运行在目标 Pod 中，所见所得都与在 Pod 中运行无异。这种设计的妙处在于：对应用代码完全透明,无需任何修改。\n本地进程 \u0026lt;==\u0026gt; mirrord-layer \u0026lt;==\u0026gt; mirrord-agent \u0026lt;==\u0026gt; 目标 Pod 快速上手 安装 mirrord 提供了命令行工具和 IDE 插件两种方式，IDE 目前支持 VSCode、IntelliJ 等。这里以 CLI 为例。MacOS 用户可以使用 Homebrew 安装：\nbrew install mirrord Linux/其他用户可以使用安装脚本：\ncurl -fsSL https://raw.githubusercontent.com/metalbear-co/mirrord/main/scripts/install.sh | bash 配置与运行 mirrord 的核心在于配置文件，通过配置文件来指定哪些操作需要被代理到远程 Pod，哪些操作是在本地。配置文件通常位于 .mirrord/mirrord.json，例如：\n注意：为了方便阅读，下文的 JSON 配置中加入了注释，实际使用时请移除这些注释。\n{ \u0026#34;kubeconfig\u0026#34;: \u0026#34;/path/to/kubeconfig\u0026#34;, // 指定 kubeconfig 文件路径 \u0026#34;kube_context\u0026#34;: \u0026#34;context_name\u0026#34;, // 指定 kube context \u0026#34;target\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;pod/pod_name/container/container_name\u0026#34;, // 指定目标 Pod 和容器 \u0026#34;namespace\u0026#34;: \u0026#34;namespace_name\u0026#34; // 指定目标 Pod 所在的 namespace }, \u0026#34;feature\u0026#34;: { \u0026#34;env\u0026#34;: true, // 从远程读取环境变量 \u0026#34;network\u0026#34;: { \u0026#34;incoming\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;mirror\u0026#34; // 镜像流量，也可以设置为 steal（拦截流量）或 off（不作任何处理） } }, \u0026#34;fs\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;read\u0026#34; // 从远程读取 } } } 可以看到主要分成这么几块配置：\nK8s 环境相关，用来指定要连接的 K8s 集群以及目标 Pod 环境变量相关，用来指定从远程读取环境变量或者排除某些环境变量 网络相关，用来指定入站和出站流量的处理方式。 文件系统相关，用来指定从远程/本地读取文件或者排除某些文件 需要注意的是，如果当前没有目标 Pod，需要手动创建一个，并配置好相应的 RBAC。我一般是创建一个使用 busybox 镜像的 Pod，然后在其中运行一个 sleep infinity 命令。\n案例分享 最近在开发一个审计日志收集的应用，它以 sidecar 容器的方式运行在业务 Pod 中，负责业务容器审计日志的轮转、收集、发送到 AWS S3 进行存储。由于需要使用 Node 的 IAM Role 来访问 S3，本地无法模拟这种场景，因此使用 mirrord 来测试就非常适合。\n首先，需要创建一个目标 Pod，包含两个容器 app 和 dummy，用来模拟这个场景。app 负责模拟业务，定时产生日志文件，dummy 用来被 mirrord “夺舍”：\napiVersion: v1 kind: Pod metadata: name: test namespace: test spec: volumes: - name: logs emptyDir: {} containers: - name: app image: busybox command: - sh - -c - | echo \u0026#34;Starting log generator...\u0026#34; mkdir -p /var/audit-logs seq=0 while true; do seq=$((seq + 1)) timestamp=$(date -u +\u0026#34;%Y-%m-%dT%H:%M:%S.000Z\u0026#34;) echo \u0026#34;{\\\u0026#34;time\\\u0026#34;:\\\u0026#34;$timestamp\\\u0026#34;,\\\u0026#34;level\\\u0026#34;:\\\u0026#34;info\\\u0026#34;,\\\u0026#34;seq\\\u0026#34;:$seq,\\\u0026#34;msg\\\u0026#34;:\\\u0026#34;test\\\u0026#34;}\u0026#34; \u0026gt;\u0026gt; /var/audit-logs/audit.log sleep 15 done volumeMounts: - name: logs mountPath: /var/audit-logs - name: dummy image: busybox command: [\u0026#34;sh\u0026#34;, \u0026#34;-c\u0026#34;, \u0026#34;sleep infinity\u0026#34;] volumeMounts: - name: logs mountPath: /var/audit-logs 接着，配置 mirrord.json:\n{ // ... \u0026#34;target\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;pod/test/container/dummy\u0026#34;, \u0026#34;namespace\u0026#34;: \u0026#34;test\u0026#34; }, \u0026#34;feature\u0026#34;: { \u0026#34;env\u0026#34;: true, \u0026#34;network\u0026#34;: { \u0026#34;outgoing\u0026#34;: { \u0026#34;tcp\u0026#34;: true, \u0026#34;udp\u0026#34;: true, \u0026#34;filter\u0026#34;: { \u0026#34;remote\u0026#34;: [\u0026#34;169.254.169.254\u0026#34;] // (1) } } }, \u0026#34;fs\u0026#34;: { \u0026#34;mode\u0026#34;: \u0026#34;write\u0026#34;, // 从远程读写 \u0026#34;read_write\u0026#34;: [ \u0026#34;/var/audit-logs/audit.log\u0026#34; // (2) ] } } } 这里有几个特别的地方：\n使用 Node Role 需要访问 EC2 Instance Metadata Service (IMDS) 获取凭证，如果不通过 mirrord 代理到远程 Pod，本地进程会尝试直连该 IP，导致无法获取正确的 IAM Role 凭证。 虽然已经设置了 fs.mode 为 write，但还是需要将程序要访问的审计日志文件的路径设置为read_write（即从远程读写）。这是因为在默认情况下，无论选择何种文件系统模式，mirrord 都会从本地读取某些路径，比如：/var 和 /etc 等，具体列表可以查看这里。 最后通过命令行工具运行（或 IDE 插件）：\nmirrord exec -f .mirrord/mirrord.json -- go run main.go Tips 如果你的 K8s 节点使用的是 Bottlerocket OS，mirrord agent 可能因为权限不足而无法执行文件操作，因此需要在配置文件中开启特权模式： { \u0026#34;agent\u0026#34;: { \u0026#34;privileged\u0026#34;: true } } mirrord-agent Pod 必须和目标 Pod 在同一个节点。如果目标 Pod 所在的 Node 恰好达到了 Pod 的数量上限，将会导致 mirrord 运行本地程序时创建的 mirrord-agent Pod 无法调度。因此你可能需要通过 nodeSelector 等方式让目标 Pod 调度到有充足资源的 Node 上。\n如上文案例所述，mirrord 对某些路径有默认的读取行为（默认从本地读取，或从远程读取）。如果遇到文件读写不符合预期，请先检查是否命中了默认规则，必要时需在配置中显式指定 fs.local 或 fs.remote。\n如果遇到了奇怪的问题（例如无法访问一个存在的文件等），可以设置环境变量 RUST_LOG=debug 来让本地程序运行时输出更多 debug 日志：\nRUST_LOG=debug mirrord exec -f .mirrord/mirrord.json -- go run main.go 总的来说，我遇到的问题主要是配置不正确，导致文件读写或者网络访问不是发生在预期的本地或远程导致。\n总结 mirrord 真正做到了让云原生开发\u0026quot;本地化\u0026quot;，它消除了本地开发和云端测试之间的鸿沟，虽然初期在配置上有一定门槛，但一旦配置好，便能大幅提升开发效率和体验。如果你厌倦了构建、推送、部署的漫长等待，不妨试试这款“黑科技”。\n参考 mirrord 官方文档 GitHub: metalbear-co/mirrord ","date":"2025-12-28T00:00:00Z","permalink":"https://fgksgf.github.io/p/mirrord-%E5%AE%9E%E6%88%98%E6%8C%87%E5%8D%97-%E5%A6%82%E4%BD%95%E5%A4%A7%E5%B9%85%E6%8F%90%E5%8D%87%E4%BA%91%E5%8E%9F%E7%94%9F%E5%BC%80%E5%8F%91%E6%95%88%E7%8E%87/","title":"mirrord 实战指南: 如何大幅提升云原生开发效率？"},{"content":"诡异的 Pod 重启现象 几个月前，我遇到了一个令人困惑的 Kubernetes 故障：在一周的时间里，我几乎每天都会收到不同 Pod 出现 CrashLoopBackOff 状态的告警。通过 kubectl describe pod 查看重启的原因均是容器异常退出。奇怪的是，虽然这些 Pod 在同一个 K8s 集群，但属于不同的 Deployment 和 Namespace，表面上无直接的关联。然而只要我执行 kubectl delete pod 命令删除故障 Pod，让其所属的 Deployment 重新创建，Pod 便会恢复正常。\n起初，我通过简单地删除 Pod 来应对告警，但问题并没有收敛，反而持续发生，这暗示着可能存在更深层次的系统性问题。为了彻底解决问题，标本兼治，我决定深入调查，找出根本原因。\n抽丝剥茧，循序渐进 首先，通过查看日志和 K8s events，发现均是因为网络问题导致 Pod 重启，例如：\nPod A 日志显示：dial tcp: lookup kube-apiserver on 172.20.0.10:53: no such host。该应用依赖 K8s apiserver 才能正常工作，但日志表明容器无法解析 IP 地址（尽管集群内的 coredns 组件运行正常），因此异常退出进而不断重启 Pod B 的日志为 timeout: failed to connect service \u0026quot;:50051\u0026quot; within 5s，其中 50051 是容器的 liveness probe 端口，由于 kubelet 一直探测失败所以不断重启容器 由于 Pod B 属于 DaemonSet，我注意到了这两个 Pod 都运行在 Node C 上。回顾之前的告警，发现受影响的 Pod 也都是跑在 Node C 上。而之前的 kubectl delete pod 操作恰好使得告警的 Pod 被重建后调度到了其他 Node 上，从而恢复了正常，这表明问题根源在 Node C。\n于是我立即使用kubectl cordon将 Node 标记为不可调度，在接下来的几天果然没有再出现类似的告警，但根本原因还没有定位出来。\n我查看了 Node 的 metrics 和 events，资源使用情况正常，未发现明显瓶颈。最后在 Node 的 /var/log/messages 中发现了关键的日志信息：\u0026ldquo;nf_conntrack: nf_conntrack: table full, dropping packet\u0026rdquo;。\nnf_conntrack 是 Linux 系统中 Netfilter 的一个关键组件，用于跟踪所有网络连接。上述日志表明连接跟踪表（conntrack table）已满，操作系统无法为新的网络连接创建条目。conntrack table 满的原因可能是 Node 上的某个异常 Pod 占用了大量连接。该 Pod 可能建立了大量连接，但未及时释放，导致 conntrack table 无法回收连接。当 Node 上的其他 Pod 尝试建立新连接时，由于 conntrack table 已满，连接失败，或是无法访问 coredns 解析 IP 地址或是 kubelet 无法探活成功，进而导致 Pod 重启。\n拨开迷雾，找到元凶 定位到了问题，接下来就是找出 Node 上的异常 Pod。\n由于 Kubernetes 使用了网络命名空间来确保 Pod 之间的网络隔离，因此直接在 Node 查看连接状态可能无法准确反映单个 Pod 的网络活动，我们需要进入到 Pod 的网络命名空间去查看连接情况。故基本思路为：逐个检查 Pod 的网络命名空间，查看当前建立的连接数量。\n首先通过kubectl describe node拿到 Node 上所有的 Pod 信息，再使用以下命令拿到容器 ID：\n# 由于 Pod 中所有容器共享同一命名空间，只需查询一个容器即可 kubectl get pod \u0026lt;POD-NAME\u0026gt; -n \u0026lt;NAMESPACE\u0026gt; -o jsonpath=\u0026#39;{.status.containerStatuses[0].containerID}\u0026#39; 然后在 Node 上执行以下命令：\n# 获取容器的 PID： crictl inspect --template \u0026#34;{{ .info.pid }}\u0026#34; -o go-template \u0026lt;ContainerID\u0026gt; # 统计该 Pod 网络命名空间中所有打开的网络连接数 nsenter -t \u0026lt;pid\u0026gt; -n netstat -anp | wc -l 最终发现，有一个 Pod 建立了异常多的连接，明显高于该 Node 上其他 Pod。\n查看对应的代码，该应用是一个 K8s Operator，它在每一次 reconcile 的时候都会创建一个 http.Client 并发起若干次请求。由于没有进行额外的设置，下面这些配置均会使用默认值，这意味着每次 reconcile 都可能导致连接泄漏：\n// MaxIdleConns controls the maximum number of idle (keep-alive) // connections across all hosts. Zero means no limit. MaxIdleConns int // IdleConnTimeout is the maximum amount of time an idle // (keep-alive) connection will remain idle before closing // itself. // Zero means no limit. IdleConnTimeout time.Duration // DisableKeepAlives, if true, disables HTTP keep-alives and // will only use the connection to the server for a single // HTTP request. // // This is unrelated to the similarly named TCP keep-alives. DisableKeepAlives bool 亡羊补牢，永绝后患 为了避免类似问题再次发生，我采取了以下措施：\n修改代码，对闲置连接的相关配置项进行合理设置而非使用默认值 增加了对 Node conntrack table 使用情况的监控面板，并添加了相应的告警规则 (node-exporter 暴露了 conntrack 相关的 metrics): - alert: NodeHighNumberConntrackEntriesUsed annotations: description: \u0026#39;{{ $value }} of conntrack entries are used.\u0026#39; runbook_url: https://runbooks.prometheus-operator.dev/runbooks/node/nodehighnumberconntrackentriesused/ summary: Number of conntrack are getting close to the limit. expr: node_nf_conntrack_entries / node_nf_conntrack_entries_limit \u0026gt; 0.7 for: 10m （可选）根据节点的内存调整 conntrack table 大小： vim /etc/sysctl.conf net.netfilter.nf_conntrack_max = \u0026lt;value\u0026gt; sysctl -p /etc/sysctl.conf 总结与反思 在本次故障排查的过程中，有两个关键行动点：\n识别模式：通过观察多个故障案例，找出了共同点，有效缩小了问题排查的范围 多角度排查：在问题排查过程中，除了分析 Node 的 metrics、events 和 kubelet 日志外，还检查了 Node 的系统日志，这提供了额外的视角和信息 整个过程凸显了 Kubernetes 生态的复杂性。为了成功地发现和解决问题，我们不仅需要深入理解 K8s 各组件的工作原理，还需要具备深入的操作系统级别知识。这些知识帮助我们穿透表象，直击问题核心。\n总的来说，尽管问题的出现带来了不小的挑战，但解决过程本身也是一次宝贵的学习经历。\nReferences https://thenewstack.io/hackers-guide-kubernetes-networking/ ","date":"2024-05-02T00:00:00Z","permalink":"https://fgksgf.github.io/p/kubernetes-%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%AE%9E%E5%BD%95pod-%E8%BF%9E%E7%8E%AF%E9%87%8D%E5%90%AF/","title":"Kubernetes 故障排查实录：Pod 连环重启"},{"content":"背景 在上一篇博客里搭建了一个具有三个节点的 k8s 集群，可以用来跑一些应用了，但是对于各个节点的健康状况、资源利用率这些信息目前还需要手动 ssh 到虚拟机上去查看，非常低效，这非常不云原生，因此这篇博客记录一下安装各种工具来以可视化的方式监控 k8s 集群。\nK8s Dashboard 首先想到的是 k8s dashboard，它是 k8s 官方提供的 Web UI，可以用来查看集群的概览信息和各个资源对象的运行情况。部署很简单，只需要执行一条命令，执行完后会默认部署在 kubernetes-dashboard 命名空间下：\nkubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.5.0/aio/deploy/recommended.yaml 为了以集群管理员的身份来访问 dashboard，还需要创建一个ServiceAccount，并与cluster-admin这个ClusterRole绑定：\n# dashboard-sa.yaml kind: ClusterRoleBinding apiVersion: rbac.authoriztion.k8.io/v1 metadata: name: admin roleRef: kind: ClusterRole name: cluster-admin apiGroup: rbac.authorization.k8s.io subjects: - kind: ServiceAccount name: admin namespace: kube-system --- apiVersion: v1 kind: ServiceAccount metadata: name: admin namespace: kube-system 然后执行kubectl apply -f dashboard-sa.yaml，创建完成后找到这个ServiceAccount对应的Secret及 token：\nkubectl -n kube-system get secret | grep admin-token admin-token-v82gm kubernetes.io/service-account-token 3 27d # 获取 token kubectl describe secret admin-token-v82gm -n kube-system 需要注意的是，从v1.24开始，创建ServiceAccount之后不会自动生成Secret了，需要先手动创建：\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: v1 kind: Secret type: kubernetes.io/service-account-token metadata: name: admin-token namespace: kube-system annotations: kubernetes.io/service-account.name: \u0026#34;admin\u0026#34; EOF 然后再使用kubectl describe secret admin-token -n kube-system获取 token。\n最后执行kubectl proxy，通过 http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/ 访问 Dashboard，在认证页面输入前面得到的 token 即可。\nNode Exporter 此外，可以通过 NodeExporter 来将节点的 CPU、内存等使用信息暴露出来供 Prometheus 采集，进而使用 Grafana 进行可视化。NodeExporter 的部署也很简单，它以DaemonSet的形式部署在每个节点上：\n# node-exporter.yaml apiVersion: apps/v1 kind: DaemonSet metadata: labels: app.kubernetes.io/component: exporter app.kubernetes.io/name: node-exporter name: node-exporter namespace: monitoring spec: selector: matchLabels: app.kubernetes.io/component: exporter app.kubernetes.io/name: node-exporter template: metadata: labels: app.kubernetes.io/component: exporter app.kubernetes.io/name: node-exporter spec: tolerations: # this toleration is to have the daemonset runnable on master nodes # remove it if your masters can\u0026#39;t run pods - key: node-role.kubernetes.io/master operator: Exists effect: NoSchedule containers: - args: - --path.sysfs=/host/sys - --path.rootfs=/host/root - --no-collector.wifi - --no-collector.hwmon - --collector.filesystem.ignored-mount-points=^/(dev|proc|sys|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/) - --collector.netclass.ignored-devices=^(veth.*)$ name: node-exporter image: quay.io/prometheus/node-exporter:latest ports: - containerPort: 9100 protocol: TCP resources: limits: cpu: 400m memory: 500Mi requests: cpu: 200m memory: 200Mi volumeMounts: - mountPath: /host/sys mountPropagation: HostToContainer name: sys readOnly: true - mountPath: /host/root mountPropagation: HostToContainer name: root readOnly: true volumes: - hostPath: path: /sys name: sys - hostPath: path: / name: root --- kind: Service apiVersion: v1 metadata: name: node-exporter namespace: monitoring annotations: prometheus.io/scrape: \u0026#39;true\u0026#39; prometheus.io/port: \u0026#39;9100\u0026#39; labels: app.kubernetes.io/component: exporter app.kubernetes.io/name: node-exporter spec: selector: app.kubernetes.io/component: exporter app.kubernetes.io/name: node-exporter ports: - name: node-exporter protocol: TCP port: 9100 targetPort: 9100 Prometheus Operator 然后通过 Prometheus Operator 来部署 Prometheus 实例来采集 NodeExporter 的数据。\n需要注意的是，必须使用create而不是apply，否则会报错。因为 yaml 中的 CRD 内容本来就很长，使用apply会在kubectl.kubernetes.io/last-applied-configuration这个注解里填入整个 CRD 使得内容长度超过限制。\nkubectl create -f https://raw.githubusercontent.com/prometheus-operator/prometheus-operator/master/bundle.yaml Prometheus Operator 部署成功后，需要创建一个ServiceMonitor的CR，用来通过标签来选中Service对象进行爬取 metrics。以爬取 NodeExporter 为例：\napiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: name: node-exporter namespace: monitoring labels: layer: infra spec: # NodeExporter Service 所在的 namespace namespaceSelector: matchNames: - monitoring selector: # NodeExporter Service 的 label matchLabels: app.kubernetes.io/component: exporter app.kubernetes.io/name: node-exporter endpoints: # NodeExporter Service metrics port 名称 - port: node-exporter relabelings: - sourceLabels: [__meta_kubernetes_pod_node_name] targetLabel: instance 最后部署 Prometheus 类型的 CR 部署 Prometheus 实例，通过标签来选中对应的ServiceMonitor对象：\napiVersion: monitoring.coreos.com/v1 kind: Prometheus metadata: name: instance spec: serviceAccountName: prometheus # 选中 ServiceMonitor serviceMonitorSelector: matchLabels: layer: infra resources: requests: memory: 500Mi cpu: \u0026#34;0.5\u0026#34; 此外需要为该实例使用的ServiceAccount配置相关的权限（略）。\nGrafana Prometheus 采集到监控数据后，可以通过 Grafana 进行展示。\n这里通过以下 YAML 部署使用 emptyDir 的 Grafana （pod从节点上删除时，数据会丢），并通过NodePort的方式暴露服务：\n--- apiVersion: apps/v1 kind: Deployment metadata: labels: app: grafan name: grafana spec: selector: matchLabels: app: grafana template: metadata: labels: app: grafana spec: securityContext: fsGroup: 472 supplementalGroups: - 0 containers: - name: grafana image: grafana/grafana:8.4.4 imagePullPolicy: IfNotPresent ports: - containerPort: 3000 name: http-grafana protocol: TCP readinessProbe: failureThreshold: 3 httpGet: path: /robots.txt port: 3000 scheme: HTTP initialDelaySeconds: 10 periodSeconds: 30 successThreshold: 1 timeoutSeconds: 2 livenessProbe: failureThreshold: 3 initialDelaySeconds: 30 periodSeconds: 10 successThreshold: 1 tcpSocket: port: 3000 timeoutSeconds: 1 resources: requests: cpu: 250m memory: 750Mi volumeMounts: - mountPath: /var/lib/grafana name: grafana-pv volumes: - name: grafana-pv emptyDir: {} --- apiVersion: v1 kind: Service metadata: name: grafana spec: selector: app: grafana sessionAffinity: None type: NodePort ports: - targetPort: 3000 nodePort: 32000 port: 3000 进入 Grafana 的页面，初始账号和密码都是admin。\n参考 使用 kubeconfig 或 token 进行用户身份认证 · Kubernetes 中文指南——云原生应用架构实战手册\n部署和访问 Kubernetes 仪表板（Dashboard） | Kubernetes\n什么是Prometheus Operator - prometheus-book\nHow To Setup Grafana On Kubernetes - Beginners Guide\nhttps://github.com/prometheus-operator/prometheus-operator/issues/1166\nhttps://blog.container-solutions.com/prometheus-operator-beginners-guide\n监控 Kubernetes 集群节点-阳明的博客|Kubernetes|Istio|Prometheus|Python|Golang|云原生\nhttps://itnext.io/big-change-in-k8s-1-24-about-serviceaccounts-and-their-secrets-4b909a4af4e0\n","date":"2022-03-15T00:00:00Z","permalink":"https://fgksgf.github.io/p/%E7%9B%91%E6%8E%A7-kubernetes-%E9%9B%86%E7%BE%A4/","title":"监控 Kubernetes 集群"},{"content":"背景 手边有几台闲置的 Windows 台式机，于是准备充分利用一下这些闲置的计算资源，使用 kubeadm 搭建一个最新版本的 k8s 集群用于自己学习和研究。\n这几台 PC 在一个局域网内可以互相连同和访问公网，但没有公网 IP。其配置如下，PC 1 用来作主节点，其他两台作为工作节点。\nOS 配置 IP VM 配置 VM IP VM Hostname PC 1 Win 10 4核8G 192.168.2.38 2核4G 192.168.2.80 master PC 2 Win 10 4核24G 192.168.2.24 3核16G 192.168.2.84 worker-4c16g PC 3 Win 10 4核16G 192.168.2.51 3核8G 192.168.2.81 k8s-worker 准备 首先在所有 PC 上安装好 VirtualBox，在 PC 1（主节点）上下载好 Ubuntu Server 20.04 的镜像，安装虚拟机，具体过程可参考这里，其中有几个需要注意的地方：\n确保虚拟机分配的 CPU 数量大于 2 但小于宿主机实际的 CPU 数量，否则 kubeadm 初始化的时候会报错\n30G 硬盘，4G 以上内存\n安装过程会有个安装软件/工具的页面，除了 OpenSSH Server 以外其他都不安装，特别是 Docker，不要勾选安装（因为会使用 snap 进行安装导致 kubelet 检测不到 Docker 服务）\n主节点 首先在主节点安装好所需的软件，然后再将该虚拟机复制到其他 PC 上，从而省去重复安装和配置的过程。\n# 设置 hostname，用于区分不同的虚拟机 sudo hostnamectl set-hostname master --static 软件安装 使用阿里云的镜像仓库，避免因网络问题无法拉取镜像。\nDocker curl -fsSL https://get.docker.com | sudo sh -s -- --mirror Aliyun sudo usermod -aG docker $USER sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u0026lt;\u0026lt;-\u0026#39;EOF\u0026#39; { \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;], \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;100m\u0026#34; }, \u0026#34;storage-driver\u0026#34;: \u0026#34;overlay2\u0026#34;, \u0026#34;registry-mirrors\u0026#34;: [\u0026#34;https://bdbdr6uo.mirror.aliyuncs.com\u0026#34;] } EOF sudo systemctl daemon-reload sudo systemctl restart docker K8s # 添加并信任APT证书 curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | sudo apt-key add - # 添加源地址 add-apt-repository \u0026#34;deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main\u0026#34; sudo apt update \u0026amp;\u0026amp; apt install -y kubelet kubeadm kubectl 复制虚拟机 在 VitrualBox 界面将虚拟机关机后，右键复制，选择保存的路径，需要注意：\n设置重新生成 MAC 地址\n不保留硬件 UUID\n完全复制\n然后通过 U 盘或移动硬盘将复制的虚拟机拷贝到另外两台电脑上，打开 VirtualBox，点击注册，选择复制的虚拟机文件。\n网络配置 在虚拟机关机状态下，在虚拟机设置中将网络设置为桥接网络，相当于在局域网中虚拟出一台新主机，然后启动虚拟机，切换到 root 用户，接下来的操作都用 root 进行操作。\n通过命令vim /etc/netplan/00-installer-config.yaml配置静态 IP 地址：\nnetwork: ethernets: enp0s3: dhcp4: false # 关闭动态分配 IP addresses: [192.168.2.81/24] # 设置一个和宿主机同网段的 IP，并确保该 IP 未被占用 gateway4: 192.168.2.1 # 与宿主机一致 nameservers: addresses: [8.8.8.8, 8.8.4.4] # 与宿主机一致 version: 2 修改完成后保存，执行：netplan apply，然后测试虚拟机之间是否能够 ping 通以及访问外网。\n集群初始化 在主节点上，以 root 用户执行：\nkubeadm init --image-repository=\u0026#39;registry.cn-hangzhou.aliyuncs.com/google_containers\u0026#39; # 安装网络插件 kubectl apply -f \u0026#34;https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d \u0026#39;\\n\u0026#39;)\u0026#34; kubeadm init成功后会显示类似信息，复制用于工作节点加入集群：\nkubeadm join 192.168.2.80:6443 --token szeip3.tm5ji5ajpa6xfk64 \\ --discovery-token-ca-cert-hash sha256:f256bb87bb7d80eca7e620562a1adcbadbdc0ecd799da659403d193cb3dc3037 其中的 token 24 小时后过期，过期后可通过kubeadm token create --print-join-command再次获取上面的信息。\n在工作节点以 root 执行前面复制的 kubeadm join 命令即可加入集群。\n在主节点上查看节点：\nexport KUBECONFIG=/etc/kubernetes/admin.conf kubectl get nodes 应该可以看到三个节点，且都是Ready状态，然后只有主节点有 role 字段，两个工作节点没有，可以通过以下命令来设置：\nkubectl label node \u0026lt;node name\u0026gt; node-role.kubernetes.io/worker=worker 使用kubectl get pod -n kube-system查看核心组件的运行情况。\nSSH 配置（可选） 为了便于 SSH 到各 k8s 节点上，可以进行以下配置：\n免密码登陆 在各虚拟机上通过sudo vim /etc/ssh/sshd_config编辑 sshd 的配置文件，允许 root 登陆和使用公钥认证:\nPermitRootLogin yes PubkeyAuthentication yes 保存后重启 sshd 服务：service sshd restart\n在个人 PC 上：\n# 将公钥复制到虚拟机上 scp ~/.ssh/id_rsa.pub root@192.168.2.81:~/.ssh/ 在虚拟机上：\ncat ~/.ssh/id_rsa.pub \u0026gt;\u0026gt; authorized_keys 快捷连接 在个人 PC 上给 ssh 的虚拟机设置别名，从而实现执行ssh master就能连接虚拟机，而无需记忆 IP 地址：\nvim ~/.ssh/config Host master user root hostname 192.168.2.80 port 22 IdentityFile /Users/hoshea/.ssh/id_rsa Host worker1 user root hostname 192.168.2.84 port 22 IdentityFile /Users/hoshea/.ssh/id_rsa Host worker2 user root hostname 192.168.2.81 port 22 IdentityFile /Users/hoshea/.ssh/id_rsa 参考 k8s 国内源安装备忘清单 · Issue #212 · islishude/blog · GitHub ","date":"2022-03-11T00:00:00Z","permalink":"https://fgksgf.github.io/p/%E4%BD%BF%E7%94%A8%E9%97%B2%E7%BD%AE%E7%9A%84-windows-pc-%E6%90%AD%E5%BB%BA-k8s-%E9%9B%86%E7%BE%A4/","title":"使用闲置的 Windows PC 搭建 k8s 集群"},{"content":"正文 在 2021 年 4 月的时候，我开始找实习。由于实验室管的比较严，每天都需要打卡四次，一周溜出去实习三四天感觉不太现实，所以倾向于找能够远程的实习。当时也面了某大厂，但是因为不能远程，所以就没去。机缘巧合下，看到了 PingCAP 的公众号推文，他们正好在招实习生，做混沌工程，我看了一下岗位的需求，觉得还满匹配的，于是满怀期待地投了。因为之前不时会看到 PingCAP 相关的资讯，在国内开源界有一定名气，也听说是一家“remote friendly”的公司，心想如果能去那里实习那就太好了。\n然而没想到，几个星期过去，犹如石沉大海般没有音讯，于是又在牛客网投递了一遍。大概过了一周还是没有消息，心想难道是因为我没有找内推？于是我一边在牛客网上私信 HR 询问进展，一边在 GitHub 上找了一位 PingCAP 员工，询问了一下他能否内推，结果被告知没有 HC 了，无奈只得作罢。\n但就在被告知没有 HC 的第二天，HR 联系上了我，说我投递的混沌工程的实习岗没有 HC 了，但另一个 team 现在有 HC，做 Database as a Service (DBaaS) 的，问我是否可以。当时又惊又喜，果断答应，约了面试时间。挂完电话感觉自己像在做梦一样，没想到事情变幻地如此之快，现在看来就好像冥冥之中安排好了似的\u0026hellip;\u0026hellip;\n之后经过两轮技术面和一轮 HR 面，在 6 月入职了。当时和 leader 约定好：每周的二、三、五远程实习三天，每两周来一次公司，还是挺不错的。\n在实习初期，主要是在看文档，学习架构和项目用到的工具，活不是很多，还算比较轻松，但是实验室这边导师在催促论文的进度，所以会占用不少时间，一周七天里可能两边分配的时间五五开。到实习的中后期，论文投出去了，就主要把精力放在了实习上，虽然可能约定的是一周三天，但可能有四天都在工作，然后在周末花一天时间做一下实验室的任务应付一下导师。\n最后说一下实习的收获吧。在这 8 个月的实习中，接触和学习到了很多新东西，比如 GitOPS、Infrastructure as Code（IaC）等，也对公有云产品里面的各种复杂的概念有了一定的了解。此外就是对 k8s 的理解更深刻了一些。在实习之前，对 k8s 的掌握还比较粗浅，仅停留在了使用 kubectl 的几个常用命令，经过在实际工作中的大量使用，对 k8s 的学习也就更加深入了一些，一些原本可能需要死记硬背的东西就很自然地记在了脑中，费曼学习法诚不欺我。\n因为我的实习时间比较零碎，所以做的工作也是一些比较零碎的事情，主要集中在 CI/CD 和可观测性两方面，没有比较完整地参与到某个大 feature 的开发和上线过程，这可能是我实习的唯一一个遗憾吧。但总的来说还是挺享受这次实习的，很满意贵司的氛围和福利，最后也转正选择了留在 PingCAP，期待毕业后的正式入职。\n","date":"2022-02-26T00:00:00Z","permalink":"https://fgksgf.github.io/p/%E5%AE%9E%E4%B9%A0%E5%B0%8F%E8%AE%B0/","title":"实习小记"},{"content":"前言 2017年，我在知乎受到启发，决定动手搭建一个自己的博客。一番搜索之后，得知 Github 的每一个用户都可以定制一个自己的 github page。当时正好看到了 黄玄 大佬的简洁精致的博客，遂决定照猫画虎，照着他写的教程一步一步搭建环境，摸索修改各种参数，最后有了第一个博客。\n然而最近我想要在博客上发表新的文章的时候，碰到了一个问题：如果我想要在发表前在本地预览效果，我必须重配环境，因为当时是在原来的电脑上搭建的，否则只能 push 到 GitHub 上预览，这样十分麻烦。\n于是在2018年决定使用 Hexo 重新搭建一个博客，它只需要 Node.js 环境和 git，而之前的 Jekyll 需要安装 Ruby 环境。把 Hexo 官网上几乎所有主题都看了一遍以后，我最后选择了 raytaylorism 主题。\n现在是2020年12月，在我的2020年的 flag 中有这么一条：Perfect blog，眼看2020年即将过去，于是决定抓住2020的尾巴，用 Hugo 重构一下博客。\n正文 实现这个博客大概分成以下几个步骤(以 MacOS 为例)：\n1.安装 Hugo brew install hugo 2.建站 hugo new site Blog/ -f \u0026#34;yaml\u0026#34; cd Blog 3.下载主题并配置 git clone https://github.com/CaiJimmy/hugo-theme-stack/ themes/hugo-theme-stack 4.本地预览 经过以上步骤的折腾摸索，博客的框架已经搭好，接下来使用以下命令来启动服务器以预览博客:\nhugo server 5.配置 GitHub Actions 自动部署 主要参考了这篇文章。\nGitHub Actions 配置文件如下：\nname: GitHub Pages Deploy on: push: branches: - master jobs: deploy: runs-on: ubuntu-18.04 steps: - name: Checkout master uses: actions/checkout@v2 with: submodules: true fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.79.0\u0026#39; extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} publish_dir: ./public 后记 有了前两次的经历，这次还是非常高效的，大部分时间都用在了挑选主题上了。我觉得以后应该不会再变了，Hugo 还是挺香的。\n","date":"2020-12-28T00:00:00Z","image":"https://fgksgf.github.io/p/hello-hugo/helena-hertz-wWZzXlDpMog-unsplash_hu45a5e3ad5e058da6a00650ed8fd40bea_15530_120x120_fill_q75_box_smart1.jpg","permalink":"https://fgksgf.github.io/p/hello-hugo/","title":"Hello Hugo"},{"content":"背景 我是一个热爱编程、热爱技术的人，⼀直以来都向往着能参与到开源项⽬中锻炼⾃⼰，但当我面对庞大而复杂的项目代码时，却感到手足无措，不知该从何开始。⽽此次的“开源软件供应链点亮计划-暑期2020”活动则正好提供了这样⼀个机会：清晰的任务要求、开源社区成员作为导师提供指导以及一笔丰厚的奖金，让我顺利地踏上了开源这条道路。\n回顾 在“暑期2020”活动的这两个多月里，我为 SkyWalking 的命令行工具实现了一个 dashboard，此外在阅读项目源码的过程中，还发现并修复了几个 bug。到活动结束时，我共提交了11个 PR，贡献了两千多行改动，对 SkyWalking CLI 项目的贡献数量排名第二，还获得了“最具潜力奖”。\n我觉得之所以能够如此顺利地完成这个项⽬主要有两个原因。一方面，我选择的 SkyWalking CLI 项⽬当时最新的版本号为0.3.0，还处于起步阶段，代码量相对较少，⽽且项⽬结构非常清晰，文档也较为详细，这对于我理解整个项⽬⾮常有帮助，从⽽能够更快地上⼿。另一方面，我的项目导师非常认真负责，每次我遇到问题，导师都会及时地为我解答，然后我提交的 PR 也能够很快地被 review。⽽且导师不时会给予我肯定的评论与⿎励，这极⼤地提⾼了我的成就感，让我更加积极地投⼊到下⼀阶段的⼯作，形成⼀个正向的循环。\n收获 回顾整个参与过程，觉得自己收获颇多：\n首先，我学习到了很多可能在学校里接触不到的新技术，了解了开源项目是如何进行协作，开源社区是如何运转治理的，以及开源文化、Apache way 等知识，仿佛进入了一个崭新而精彩的世界。\n其次，我的编程能力得到了锻炼。因为开源项目对于代码的质量有较高的要求，因此我会在编程时有意识地遵守相关的规范，培养良好的编码习惯。然后在导师的 code review 中也学习到了一些编程技巧。\n此外，参与开源为我的科研带来了不少灵感。因为我的研究方向是智能软件工程，旨在将人工智能技术应用在软件工程的各个环节中，这需要我在实践中发现实际问题。而开源则提供了这样一个窗口，让我足不出户即可参与到软件项目的设计、开发、测试和发布等环节。\n最后也是本次活动最大的一个收获，我的贡献得到了社区的认可，被提名成为了 SkyWalking 社区的第一位学生 committer。\n建议 最后，对于将来想要参加此类活动的同学，附上我的一些建议：\n第一，选择活跃、知名的社区。社区对你的影响将是极其深远的，好的社区意味着成熟的协作流程、良好的氛围、严谨的代码规范，以及有更大几率遇到优秀的导师，这些对于你今后在开源方面的发展都是非常有帮助的。\n第二，以兴趣为导向来选择项目，同时要敢于走出舒适区。我最初在选择项目时，初步确定了两个，一个是低难度的 Python 项目，另一个是中等难度的 Go 项目。当时我很纠结：因为我对 Python 语言比较熟悉，选择一个低难度的项目是比较稳妥的，但是项目的代码我看的并不是很懂，具体要怎么做我完全没有头绪；而 Go 项目是一个命令行工具，我对这个比较感兴趣，且有一个大致的思路，但是我对 Go 语言并不是很熟悉，实践经验为零。最后凭借清晰具体的 proposal 我成功申请到了 Go 项目并顺利地完成了，还在实践中快速掌握了一门新的编程语言。\n这次的“暑期2020”活动虽已圆满结束，但我的开源之路才刚刚开始。\n补充资料 [1] 暑期2020申请报告、中期报告、结项报告：https://github.com/fgksgf/Summer-2020\n","date":"2020-12-19T00:00:00Z","permalink":"https://fgksgf.github.io/p/%E6%9A%91%E6%9C%9F2020%E6%B4%BB%E5%8A%A8%E5%BF%83%E5%BE%97/","title":"暑期2020活动心得"},{"content":"正文 前段时间发现住我对面寝室的“远房室友”是知乎大V，获得了几十万赞同的那种。进入他的知乎主页，他的昵称和微信名一样，他的本科学校、读研学校和所学专业等信息一览无余……这让我不禁想到自己，与室友几乎是完全相反，我向来不喜欢在网上公布自己真实信息，甚至总是尽可能的隐藏这些信息。\n大概就像《疑犯追踪》里 Harold 所说，我是一个非常注重隐私的人。我的这个习惯大概是从我看完一本讲社会工程的书后开始养成的，那时我才知道，原来黑客不仅仅只是活跃在虚拟的网络世界里，现实世界也有，而且更加让人防不胜防。对于精通社会工程的黑客来说，无论是渗透入侵多么复杂严密的系统，只要有人的存在，这个系统就不是安全的，因为人类就是这个系统最大的漏洞。\n如果你是第一次听说社会工程，可能会觉得我在胡说八道。但你肯定听说过人肉搜索,它可以算是社会工程的一种。\n社会工程是一种通过欺骗、假冒、伪造和心理学等手段操纵和控制人们，以使其执行特定动作或泄露敏感信息的行为，而不是通过侵入或使用计算机技术来实现的。\n生活中最常见的例子可能就是电信诈骗了，冒充官方人员打电话给你说你的银行账户出现问题之类，或者告诉你你的亲人发生意外等……\n我曾试着用搜索引擎人肉搜索自己，就从自己的手机号开始，在搜索结果里看到了自己的名字、本科学校、专业、班级等信息。再用名字，搜索看到了自己的初中、高中、大学和一些获奖信息……令人触目惊心。\n在这个互联网高度发达的时代，想要在网络上保护和隐藏自己的信息变得格外困难，而社交网络的出现，又使其难度更上一层楼。要想不被社工和人肉，不仅自己要有防范意识，采取一些措施，还要让自己身边的人也做到这点，这不太现实。\n到目前为止，我养成了以下这些习惯来保护自己的信息，仅供参考：\n尽可能在不同的社交媒体采用不同的昵称或用户名，昵称和用户名中不包含任何个人信息（生日、名字等） 关闭所有类似“通过手机号找到我”这种功能（支付宝、微信） 社交媒体上的个人资料不要过于真实 :P 朋友圈、QQ空间等不对陌生人开放 将快递单上的个人信息部分“手动打码”或“手动碎纸”后再丢弃 网上购物时收货人名字不填真实名字 用专门的一个不常用的邮箱和手机号用于注册 注册国外的一些网站需要填详细的个人信息时，可以用这个 在线工具 生成虚假的信息（包含名字，住址，手机号等） 不与可能暴露个人信息的实体互动，例如在百度贴吧中关注母校贴吧等行为 关闭照片附带地理信息功能 （以后想到再慢慢更新）…… 还有一条我自己也很难做到：“不在社交媒体中与熟人互动”。因为微博和b站的关注列表中一般会有自己的朋友和同学，而他们不经意间泄露的个人信息可能就会导致自身的信息被泄露……\n","date":"2019-11-20T00:00:00Z","permalink":"https://fgksgf.github.io/p/%E6%B5%85%E8%B0%88%E4%B8%AA%E4%BA%BA%E4%BF%A1%E6%81%AF%E4%BF%9D%E6%8A%A4/","title":"浅谈个人信息保护"},{"content":"背景 在众多不同的数据模型里，关系数据模型自20世纪80年代起就处于统治地位。它建立在严格的数学基础上, 具有较高的数据独立性和安全性, 使用简单，同时也是目前应用最为广泛的数据技术。然而，使用范围不断扩大的关系数据库，随着大数据时代的到来，也逐渐暴露出了一些它无法解决的问题，主要是数据建模中的一些缺陷，及其在大数据量和多服务器之上进行水平扩展的限制。同时，互联网的高速发展也催生了一些新的趋势变化：如用户、系统和传感器产生的数据量呈指数级增长，因大部分数据量集中在Amazon、Google和其他云服务的分布式系统上，其增长速度进一步加快；又如，数据内部依赖和复杂度急剧增加，这一问题因Web2.0、社交网络，以及对大量不同系统的数据源开放和标准化的访问而愈加明显。\n在应对这些趋势时，关系数据库产生了很多的不适应性，从而导致大量新技术的出现，以解决关系数据库无法高效处理的问题。这些技术往往针对问题中的某些特定方面，它们可以与现有RDBMS相互配合、或代替它们——亦被称为混合持久化。基于此，在过去几年间，大量的新项目或新产品出现，它们被统称为NoSQL（Not only SQL，不限于SQL）数据库。\nNoSQL数据库是一类涵盖范围非常广泛的持久化解决方案，它们不遵循关系数据库模型，也不使用SQL作为查询语言。它们的数据存储可以不需要固定的表格模式，经常避免使用SQL的JOIN操作，一般具有水平可扩展的特征。\n按照数据模型的不同，NoSQL数据库可分成4类，分别是键-值存储库、列存储数据库、文档数据库和图数据库。从最近十年的发展趋势来看，图数据库已经成为关注度最高、最有发展和应用潜力的数据库类型。\n如下图所示，DB-Engines对近六年来所有数据模型的数据库进行了发展趋势的分析，结果如下图所示：\n可以明显的看出，图数据库正获得越来越多的关注。\n简介 Neo4j是一个高性能、高可靠性、可扩展、支持ACID事务的图数据库，它基本由Java语言实现，支持数据平台的平滑扩展和过渡，同时能够在多种系统上完成部署。它使用Cypher查询语言对数据进行增删查改。相对于关系数据模型而言，Neo4j重点解决了拥有大量连接的传统RDBMS在查询时出现的性能衰退问题。\n数据模型 Neo4j采用属性图模型对数据进行建模，能够以相同的速度遍历结点与边，其遍历速度与构成图形的数据量没有任何关系。属性图模型中包含四种构造元素：\n节点，即顶点，主要的数据元素 关系，即边，具有方向和类型 节点和关系上的属性，存储为键值对的形式 标签，用于描述节点在图表中的角色，以及将节点分组 应用场景 图数据库主要有以下典型应用场景：\n欺诈检测和分析 传统的防欺诈措施侧重于离散数据点，如特定帐户，个人，设备或IP地址。然而，今天复杂的欺诈者通过形成由被盗和合成身份组成的欺诈环来逃避侦查。要发现此类欺诈响应，必须超越单个数据点以查找链接它们的连接。Neo4j可以揭示了难以检测的模式，因此很多企业组织使用Neo4j来增强其现有的欺诈检测功能，以实时打击各种金融犯罪，包括第一方银行欺诈，信用卡欺诈，电子商务欺诈，保险欺诈和洗钱。\n知识图谱 无论是利用已宣布的社交关系还是根据活动推断关系，Neo4j在创建社交网络或将当前社交图谱集成到企业应用程序中时都提供了新的可能性。社交媒体网络已经是图形，因此没有必要将图形转换为表格然后再转换回来。使用Neo4j可以减少花费数据建模的时间，从而提高社交网络应用程序的开发质量和速度。\n推荐引擎和产品推荐系统 实时推荐引擎是任何在线业务成功的关键。要实时提出相关建议，需要能够关联产品，客户，库存，供应商，物流甚至社会情绪数据。此外，实时推荐引擎需要能够即时捕获客户当前访问中显示的任何新兴趣 - 批处理无法完成的任务。匹配历史和会话数据对于像Neo4j这样的图形数据库来说是微不足道的。实现实时建议的关键技术是图形数据库，这种技术很快就会使传统的关系数据库落后。图形数据库轻松胜过关系型和其他NoSQL数据存储，用于连接大量买方和产品数据（以及一般的连接数据），以深入了解客户需求和产品趋势。\n社交媒体和社交网络图 管理组织不断增长的数字资产库需要高度上下文的搜索解决方案。使用Neo4j可以使用知识图谱（即基于图形的搜索功能）来增强企业搜索功能，从而仅提供相关结果。例如，可以使用与关键字相关的其他结果来扩充简单的关键字搜索，而无需在搜索中明确请求。基于Neo4j的知识图谱搜索被公司用于提高产品，服务，内容和知识目录的搜索能力。\n开源协议 Neo4j分为社区版和企业版，企业版拥有更多的功能，而社区版使用GPLv3 license，代码托管在GitHub。\nNeo4j社区版使用GPL v3许可证，意味着用户基于Neo4j数据库社区版构建的应用程序，若仅在机构内部运行，那么不管是否闭源，都可以免费使用。\nNeo4j企业版有四种许可证，分别为：\n（1）商业许可证（付费）：Neo4j商业许可证面向需要基于Neo4j数据库开发闭源软件应用程序的用户，此类用户需遵循认购协议。协议除提供Neo4j企业版的使用权之外，还提供世界级支持和Neo4j公司的商业支持。\n（2）开发者许可证（免费）：在免费注册后，Neo4j可提供一个针对企业版的免费开发者许可证，允许用户在本地使用Neo4j企业版进行免费开发。在使用过程中，它也会连接到用户的生产服务器，同时也包括图形算法的安装程序，以及一些其他组件的安装，如Apoc或Java升级。\n（3）试用版许可证（免费）：用户可选择试用许可证，在商业试用期内体验整套的Neo4j企业版功能。试用版除软件外，也提供专家支持。\n（4）教育许可证（免费）：Neo4j社区版已经能够满足学生和教育工作者的大部分需求，如遇特殊情况需要Neo4j企业版的全套扩展和操作功能，可选择教学许可证版本。\n工具和插件 可视化工具 Neo4j Browser提供图形化界面来与图数据库进行交互。用户可以通过它执行cypher语句并得到图形化的查询结果。在Neo4j Browser中，可以看到当前数据库中的节点数目和关系数目、节点和关系的种类、属性键名、存储空间占用情况等。此外，它还提供了一些新手教程、样例数据等。\n数据迁移工具 Neo4j ETL Tool可以将关系型数据库中的数据迁移到图数据库中。它通过JDBC连接关系型数据库，然后通过图形化界面来调整参数，最终将表结构的数据转换为图数据库中的节点、关系和属性。\n数据导入工具 Neo4j提供了一个命令行批量数据导入工具import-tool，支持百亿级数据，导入效率极高，但此工具只适用于将全量数据加载到空数据库中。\n该工具对数据的要求较高，它需要CSV格式的节点数据文件和关系数据文件，且每个节点必须具有唯一标识符，即节点标识符。工具先创建所有的节点，然后通过节点标识符快速找到起点节点和终点节点从而迅速创建关系。\n导入工具不能容忍不良实体（关系或节点），导入过程中若遇到不良的实体，会导致整个导入过程失败。因此使用工具时需要添加选项来指定忽略包含错误实体的行，如忽略缺少节点的关系和忽略标识符相同的节点。\n扩展插件 Neo4j目前提供了三个开源插件：APOC、graphAlgorithms和GraphQL。\nNeo4j自3.x版本开始，引入了用户定义的过程和函数的概念，这些是某些功能的自定义实现，无法轻易地使用Cypher本身表达。由此 ，APOC（Awesome Procedures On Cypher）库诞生了，它由Java实现，可以轻松部署到Neo4j实例中，然后直接使用Cypher调用。该库包含约450个程序和函数，可支撑处理数据集成、图形算法或数据转换等多个细分领域的细分任务。\ngraphAlgorithms库提供有效实现的通用图算法的并行版本，它包含六大类图算法：\nGraphQL 是一种用于 API 的查询语言，它针对数据提供了一套易于理解的完整描述，使得客户端能够准确地获得它需要的数据，而且没有任何冗余，也让API 更容易地随着时间推移而演进，还能用于构建强大的开发者工具。Neo4j基于GraphQL架构，开发了GraphQL-Endpoint扩展。它将GraphQL查询转换为Cypher语句并在Neo4j上执行它们。它提供HTTP API以及用于执行和管理GraphQL API的Neo4j Cypher过程。\n社区情况 Neo4j的社区非常活跃，主要包括：\nNeo4j官网：涵盖对Neo4j的详细介绍、完善的使用文档、丰富的客户案例，以及软件、驱动的下载。\nNeo4j Online Community：Neo4j官方问答论坛，根据问题类型划分为了十个大版块，每个大板块下又有若干个小版块。用户可以在里面提出在使用Neo4j过程中遇到的问题，会有热心网友和Neo4j认证的员工及时解答。平均每月都有两百多个问题被提出。\nNeo4j Blog：发布Neo4j的最新动态和发展趋势，是Neo4j前沿技术的首要发布平台。\nNeo4j Github：Neo4j社区版、插件、各编程语言驱动、数据库内置工具、文档、docker镜像都托管在Github上，众多贡献者持续为Neo4j的代码仓库贡献着大量代码和知识。代码贡献者大部分都是Neo4j公司的员工。\nNeo4j 中文社区：国内最大的Neo4j中文社区，截止到2019年4月，问题总量达900条。\n性能对比 使用关系型数据库MySQL和图数据库Neo4j分别去遍历同一个具有100万个顶点和400万条边的数据集，结果如下表所示：\n遍历路径长度 Neo4j MySQL 1 27 ms 124 ms 2 474 ms 922 ms 3 3366 ms 8851 ms 4 49312 ms 112930 ms 5 862399 ms 两小时内未完成 高度连接的数据非常适合使用属性图模型来进行建模。通常来讲图数据库比传统的关系型数据库更适合高度连接的数据的一些原因是：\n（1）更好的性能。实践数据表明，高度连接的数据可能会产生大量的表连接，在超过7次的递归连接之后，与图数据库Neo4j相比，关系型数据库开始变得非常慢缓慢，具体原因下面会进行详细分析。\n（2）灵活性。图数据库不受预定义结构的约束，因此可以轻松地对数据建模、随时添加和删除属性，这对于半结构化数据尤其有用。而关系型数据库中的表在第一次插入数据时需要预先设计一个完备详细的表结构。\n（3）SQL查询困难。随着连接的增加，查询语法变得复杂和庞大。\n一般来说，时间复杂度是一个可以用来衡量查询效率的标准，复杂度越高，查询时间越久。下面通过计算关系型数据库主要应用的两种连接方式的时间复杂度，与图数据库的查询时间复杂度进行对比，从根本上说明图数据库查询复杂关系更高效的原因。\n首先是嵌套循环连接，它是最简单的连接。内部表中的每一行数据的构建，将来源于外部表的所有行的遍历读取。如果为更多表结构建立扩展连接，则时间复杂度会急剧增加。嵌套循环连接仅适用于小型表或查询的最终结果较小。\n另一种典型的多表连接方式为散列连接。散列连接是做大数据集连接时的常用方式，优化器使用两个表中数据量更小的那个表的连接键（JOIN KEY）在内存中建立临时散列表，然后遍历较大的表，找出与散列表匹配的行。\n图数据库Neo4j的优点在于，它根本不使用索引来进行连接，图数据库的节点本身存储了它第一个关系的id，通过它可以直接找到相邻节点，这种特性称为“无索引邻接”。\n同类产品对比 上图为著名的数据库排名网站DB-Engines.com根据搜索引擎查询的结果数量、Google Trends指数、提及的工作机会的数量和社交网络提及次数计算得出的流行程度得分对图数据库进行排名。可以看出，在过去六年里，Neo4j始终是最为流行的图数据库，其流行程度远远高于其他图数据库。\n下面我们主要对目前较为流行的6个开源图数据库进行了横向分析和比较：\n图数据库 开源协议 主要开发语言 关注度 贡献者数 Neo4j GPL v3 Java 6310 170 OrientDB Apache License 2.0 Java 3824 121 ArangoDB Apache License 2.0 C++ 7861 89 JanusGraph Apache License 2.0 Java 2290 100 Titan Apache License 2.0 Java 4895 33 Dgraph Apache License 2.0 Golang 9329 98 FlockDB Apache License 2.0 Scala 3188 12 综合比较来看，相比于其他图数据库，Neo4j的优势是：\n拥有极其活跃的社区 发展速度快 完善丰富的文档、驱动、插件 提供高性能图形算法库 更好的扩展性 对新架构新技术有及时的跟进和适配 其劣势是：虽然社区版是开源免费的，但是缺少例如权限控制、热备份、分布式等一些重要功能。这些功能需要付费购买昂贵的企业版才能使用。\n成功案例 目前，已经有越来越多的知名企业和政府机构开始使用图数据库Neo4j：\n世界十大零售商中的七家。像eBay和沃尔玛这样的顶级零售商依靠Neo4j来推动推荐，促销和简化物流。 五大飞机制造商中的三家。空客和波音等飞机制造商依靠Neo4j来解决复杂的连接数据问题。 十大保险公司中的八家。Bayerische和其他顶级保险公司依靠Neo4j打击欺诈和管理信息。 北美前二十的所有银行。摩根大通，花旗和瑞银等银行依靠Neo4j实现数据沿袭。 电信公司前十名中的七家。Verizon和AT＆T等领先的电信公司依靠Neo4j来管理网络和控制访问。 体系结构 内部结构 记录文件（Record Files）：数据存储层，Neo4j 将图形数据存储在许多不同的存储文件中，每个存储文件都包含图形特定部分的数据 (例如, 节点、关系、标签和属性有单独的存储区)。存储责任的划分——特别是图形结构与属性数据的分离，促进了图的高性能遍历。但这也意味着用户对其图形的视图和磁盘上的实际记录在结构上是不同的。\n页面缓存（Page cache）：页面缓存用于缓存Neo4j数据和本机索引。将图形数据和索引缓存到内存中有助于避免昂贵的磁盘访问并获得最佳性能。\n事务日志（Transaction log）：记录每一次事务的提交与执行情况，可通过查询日志中的记录进行排错处理。当Neo4j突然效率低下、或者查询负载过高时，最好的办法就是先查看日志。\nCypher（查询语言）：Cypher是一种开源的图形查询语言，其ASCII艺术风格语法提供了一种熟悉的，可读的方式来匹配图形数据集中的节点和关系模式。与SQL一样，Cypher是一种声明性查询语言，允许用户在其图形数据上声明他们想要执行的操作（例如匹配，插入，更新或删除），而无需他们描述（或编程）确切的操作方法。\n数据存储方式 Neo4j将节点、关系、属性分别存储在不同的文件中：\nneostore.nodestore.db neostore.relationshipstore.db neostore.propertystore.db neostore.propertystore.db.index neostore.propertystore.db.strings neostore.propertystore.db.arrays 其中，节点、关系和属性都采用固定大小的方式存储。固定大小的记录允许对存储文件中的节点与关系进行快速查找。如果我们有一个 id 为n的节点, 那么我们知道它的记录是从（n乘以节点字节大小）开始。根据这种格式, 数据库可以直接计算记录的位置, 时间复杂度为O(1), 而不是执行搜索, 时间复杂度将是O (log n)。\n如上图所示，每个节点记录大小为15字节。第一个字节是正在使用的标志；接下来的四个字节表示连接到节点的第一个关系的 ID；后面的四个字节表示节点的第一个属性的 ID；节点标签占用五个字节，指向此节点的标签存储区；最后一个额外字节保留给标志。节点记录非常轻量级: 它实际上只是指向关系、标签和属性的几个指针。\n关系存储结构不像节点存储那么简单。关系记录的大小为34个字节。每个关系记录都包含关系开始和结束时节点的 id、指向关系类型的指针、该关系的起点节点的下一个和上一个关系记录的指针、该关系的终点节点的下一个和上一个关系记录的指针、关系的第一个属性的ID以及指示当前关系是否是关系链中的第一个关系的标志。\n属性记录的存储采用的是单链表结构，每个属性记录由四个属性块和下一条属性记录的 ID 组成。每个属性记录占用一个到四个属性块，一条属性记录最多可以记录四个属性。属性记录包含属性类型以及指向属性索引文件 (neostore.propertystore.db.index) 的指针, 该文件是存储属性名称的地方。对于每个属性的值, 记录包含指向动态存储记录的指针或内联值。动态存储允许存储较大的属性值。有两个动态存储: 动态字符串存储 (neostore.propertystore.db.strings) 和动态数组存储 (neostore.propertystore.db.arrays)。动态记录包括固定大小记录的链接列表;因此, 一个非常大的字符串或大数组可能会占用多个动态记录。\n下图展示了Neo4j图数据库对数据的物理存储模式：\n在图中我们可以看到：两个节点记录中的每一个都包含指向该节点的第一个属性和关系链中的第一个关系的指针。若要读取节点的属性,我们从节点指向的第一个属性开始遍历链表结构的属性。若要查找节点的关系,我们从该节点的关系指针到其第一个关系 (本例中的 LIKES 关系)。然后,在这里, 我们按照该特定节点 (即起点节点双链接列表或结束节点双链接列表)的关系的双链接列表进行操作, 直到找到我们感兴趣的关系。找到所需关系的记录后, 我们可以使用与节点属性相同的单独链接列表结构读取该关系的属性(如果有的话), 也可以检查关系所连接的两个节点的节点记录使用其起始节点和结束节点 Id。这些 Id 乘以节点记录大小,给出节点存储文件中每个节点的直接偏移量。\nCypher查询语言 Cypher是一种声明性图形查询语言，允许对图形进行富有表现力和有效的查询和更新，十分适合开发人员和专业人员对针对业务场景完成一些应用。Cypher设计简单但功能强大，可以轻松完成对高度复杂的数据库的查询。Cypher查询语言的构建受到了多种方法的启发，并建立在表达性查询的既定实践基础之上。许多关键字的应用，例如“WHERR”和\u0026quot;ORDER BY\u0026quot;都受到SQL语句的启发。模式匹配借用了SPARQL中的表达式方法，而一些列表语义则是借用了Haskell和Python等语言的开发使用。\nCypher语句借鉴SQL语句结构—使用各种子句构建查询。子句链接在一起，彼此之间提供中间结果集，查询语言由几个不同的子句组成：\nMATCH：匹配的图形模式。 这是从图表中获取数据的最常用方法。 WHERE：本身不是一个子句，而是MATCH，OPTIONAL MATCH和WITH组成的一部分，用来添加对模式的约束，或过滤掉通过WITH的结果。 RETURN：返回操作。 CREATE：创建节点和关系。 DELETE：删除节点和关系。 SET 和 REMOVE：将值设置为属性并使用SET在节点上添加标签，使用REMOVE删除。 MERGE：匹配现有或创建新节点和模式。 配置数据库 neo4j.conf neo4j.conf是图数据库的配置文件，其中大多数配置直接应用于Neo4j本身，但也有一些设置适用于运行Neo4j的Java Runtime（JVM），其中：\n等号（=）将配置设置键映射到配置值； 以数字符号（#）开头的行作为注释处理； 空行被忽略； 配置设置没有顺序，neo4j.conf文件中的每个设置都必须唯一指定。如果有多个配置设置具有相同的键但值不同，则可能导致不可预测的行为。\n常用配置 编辑neo4j.conf文件：\ndbms.directories.import=\u0026lt;设置为要导入数据所在文件夹的绝对路径\u0026gt; # 初始堆和最大堆大小，建议设置为相同值 dbms.memory.heap.initial_size=4g dbms.memory.heap.max_size=4g # 运行外网访问图数据库 dbms.connector.default_listen_address=0.0.0.0 # 允许从文件系统导入csv文件 dbms.security.allow_csv_import_from_file_urls=true 插件的安装与配置 将下载的插件（jar文件）复制到‘$NEO4J_HOME/plugins’目录下。\n编辑neo4j.conf文件，添加以下内容：\ndbms.security.procedures.unrestricted=algo.*,apoc.* 验证安装，运行以下查询：\ncall algo.list() return apoc.version() 写在最后 今年2月底，去了导师那里实习，导师给我布置的任务就是研究开源图数据库。经过一番搜索，Neo4j一词频频出现在我眼前，于是便选择了它作为主要研究对象。事实证明，我的选择并没有错，因为它是目前最流行的图数据库。\n图数据库算是一个比较新的技术，国内在使用的公司很少，关于Neo4j的中文资料也很匮乏，因此Neo4j的官网就成了资料的主要来源。\n初步研究后，有幸参与到了相关产品的研发工作中，提前体验了一下996的生活；参加了一个相关的比赛，撰写了一个Neo4j技术白皮书，为集体做了一点微小的贡献。\n","date":"2019-10-10T00:00:00Z","permalink":"https://fgksgf.github.io/p/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93neo4j%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"图数据库Neo4j学习笔记"}]